{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building and evaluating different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do this:\n",
    "- Only use test data set\n",
    "\n",
    "Models to build:\n",
    "- a dummy model: mean of y\n",
    "- a baseline model: using only gender? \n",
    "- full model:\n",
    "    - a simple linear regression\n",
    "    - a non-parametric linear regression KNN\n",
    "    - a simple decision tree\n",
    "\n",
    "All? or only the full models should be trained using CV and should be heavily regularized (_standardize_ first?). \n",
    "All models should be compared using the same error metric: mean squarred error \n",
    "\n",
    "choosing the best model, validate it, and then test it:\n",
    "- investigate interpretability, feature importance, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# important relevant packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error # MSE?? rmse? \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "## random forrest og feature importance \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from xgboost import XGBRegressor\n",
    "import pickle as pkl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         51.0\n",
       "1         95.0\n",
       "2         70.0\n",
       "3         75.0\n",
       "4         82.0\n",
       "          ... \n",
       "515044    62.0\n",
       "515045    83.0\n",
       "515046    68.0\n",
       "515047    57.0\n",
       "515048    42.0\n",
       "Name: Age of death, Length: 515049, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dependent variable\n",
    "train = pd.read_csv('/work/datascience_exam/data/train.csv', index_col = 0)\n",
    "y_train = train['Age of death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# load data which has been embedded, clustered and dimensionality reduced using PCA\n",
    "# using absolute path\n",
    "X_train_w_pca_vecs = np.load('/work/datascience_exam/data/oc_pca_train.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 'United States of America', 'architect', 1888, 0,\n",
       "       0.08846393972635269, -0.012276996858417988, 0.2551751136779785,\n",
       "       -0.004892044235020876], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we want to exclude columns which are not relevant as predictors\n",
    "\n",
    "X_train_w_pca_vecs[4,0:9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train_gender = X_train_w_pca_vecs[:,0]\n",
    "X_train_predictors = X_train_w_pca_vecs[:,3:]\n",
    "\n",
    "X_train_predictors = np.hstack((X_train_gender.reshape(-1,1), X_train_predictors))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1888, 0, 0.08846393972635269], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_predictors[4,0:4]\n",
    "#X_train_predictors.shape # 51 - 3 = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 49)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0,49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# change to pd dataframe\n",
    "\n",
    "# Create list of column names with the format \"colN\" (from 1 to N)\n",
    "#col_names = ['occupation' + str(i) for i in np.arange(X_train_predictors.shape[1]) + 1]\n",
    "colnames_second = ['occupation' + str(i) for i in range(1,49)]\n",
    "\n",
    "\n",
    "colnames_first = ['gender', 'birth_year', 'occupation_cluster']\n",
    "colnames = colnames_first + colnames_second\n",
    "colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Declare pandas.DataFrame object\n",
    "\n",
    "X_train = pd.DataFrame(data=X_train_predictors, columns=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>occupation_cluster</th>\n",
       "      <th>occupation1</th>\n",
       "      <th>occupation2</th>\n",
       "      <th>occupation3</th>\n",
       "      <th>occupation4</th>\n",
       "      <th>occupation5</th>\n",
       "      <th>occupation6</th>\n",
       "      <th>occupation7</th>\n",
       "      <th>...</th>\n",
       "      <th>occupation39</th>\n",
       "      <th>occupation40</th>\n",
       "      <th>occupation41</th>\n",
       "      <th>occupation42</th>\n",
       "      <th>occupation43</th>\n",
       "      <th>occupation44</th>\n",
       "      <th>occupation45</th>\n",
       "      <th>occupation46</th>\n",
       "      <th>occupation47</th>\n",
       "      <th>occupation48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1802</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.126581</td>\n",
       "      <td>-0.030999</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>0.036347</td>\n",
       "      <td>0.446435</td>\n",
       "      <td>0.661136</td>\n",
       "      <td>-0.107335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002635</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>-0.002519</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.001413</td>\n",
       "      <td>-0.001296</td>\n",
       "      <td>-0.003087</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>-0.002874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1884</td>\n",
       "      <td>2</td>\n",
       "      <td>0.634917</td>\n",
       "      <td>-0.059081</td>\n",
       "      <td>-0.079842</td>\n",
       "      <td>-0.018078</td>\n",
       "      <td>-0.042558</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.00233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>-0.00007</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1896</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.439052</td>\n",
       "      <td>-0.390762</td>\n",
       "      <td>-0.207293</td>\n",
       "      <td>-0.003735</td>\n",
       "      <td>-0.062288</td>\n",
       "      <td>-0.011805</td>\n",
       "      <td>-0.012362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1668</td>\n",
       "      <td>2</td>\n",
       "      <td>0.634916</td>\n",
       "      <td>-0.059099</td>\n",
       "      <td>-0.079964</td>\n",
       "      <td>-0.018206</td>\n",
       "      <td>-0.042371</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1888</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088464</td>\n",
       "      <td>-0.012277</td>\n",
       "      <td>0.255175</td>\n",
       "      <td>-0.004892</td>\n",
       "      <td>0.298965</td>\n",
       "      <td>-0.388414</td>\n",
       "      <td>-0.448571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.010579</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>-0.002182</td>\n",
       "      <td>-0.011388</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-0.004653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender birth_year occupation_cluster occupation1 occupation2 occupation3  \\\n",
       "0      1       1802                  5   -0.126581   -0.030999    0.020962   \n",
       "1      2       1884                  2    0.634917   -0.059081   -0.079842   \n",
       "2      1       1896                  1   -0.439052   -0.390762   -0.207293   \n",
       "3      1       1668                  2    0.634916   -0.059099   -0.079964   \n",
       "4      1       1888                  0    0.088464   -0.012277    0.255175   \n",
       "\n",
       "  occupation4 occupation5 occupation6 occupation7  ... occupation39  \\\n",
       "0    0.036347    0.446435    0.661136   -0.107335  ...    -0.002635   \n",
       "1   -0.018078   -0.042558    0.008224     0.00233  ...     0.000065   \n",
       "2   -0.003735   -0.062288   -0.011805   -0.012362  ...    -0.000271   \n",
       "3   -0.018206   -0.042371    0.008002    0.002234  ...    -0.000157   \n",
       "4   -0.004892    0.298965   -0.388414   -0.448571  ...     0.005604   \n",
       "\n",
       "  occupation40 occupation41 occupation42 occupation43 occupation44  \\\n",
       "0     0.002376    -0.002519     0.000743     0.002733    -0.001413   \n",
       "1    -0.000137    -0.000086     -0.00002     0.000202     -0.00007   \n",
       "2     0.000968     0.000704     0.000251     0.000886     0.001017   \n",
       "3    -0.000266    -0.000387    -0.000069     0.000136     0.000148   \n",
       "4     0.010579     0.004133     0.008129    -0.002182    -0.011388   \n",
       "\n",
       "  occupation45 occupation46 occupation47 occupation48  \n",
       "0    -0.001296    -0.003087    -0.002167    -0.002874  \n",
       "1    -0.000196     0.000246     0.000274     0.000192  \n",
       "2    -0.000067     0.000192    -0.000629     0.000217  \n",
       "3     0.000249     0.000143     0.000114     0.000093  \n",
       "4     0.006734     0.000842    -0.000157    -0.004653  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing embedded features - is that what we want to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# standardize embedded data\n",
    "scaler = StandardScaler()\n",
    "#X_train_pred_scaled = scaler.fit_transform(X_train_predictors[:,3:])\n",
    "\n",
    "# pd version\n",
    "#>>> dfTest[['A', 'B']] = scaler.fit_transform(dfTest[['A', 'B']])\n",
    "\n",
    "X_train.iloc[:,3:51] = scaler.fit_transform(X_train.iloc[:,3:51])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non_scaled_cols = X_train_predictors[:,:3]\n",
    "#X_train_pred_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_train_predictors_scaled = np.hstack((non_scaled_cols, X_train_pred_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "performances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.shape\n",
    "#X_train_predictors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dummy model  -  mean of y\n",
    "\n",
    "mean_value = y_train.mean()\n",
    "model_name = 'dummy'\n",
    "performance = np.sqrt(mean_squared_error(y_train, [mean_value]*y_train.shape[0]))\n",
    "r2 = r2_score(y_train, [mean_value]*y_train.shape[0])\n",
    "performances.append({'model': model_name,\n",
    "                     'split': 'train',\n",
    "                     'rmse': performance.round(4),\n",
    "                     'r2': r2.round(4)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "### Dummy model - PD version\n",
    "\n",
    "mean_value = y_train.mean()\n",
    "model_name = 'dummy'\n",
    "performance = np.sqrt(mean_squared_error(y_train, [mean_value]*len(y_train)))\n",
    "r2 = r2_score(y_train, [mean_value]*len(y_train))\n",
    "performances.append({'model': model_name,\n",
    "                     'split': 'train',\n",
    "                     'rmse': performance.round(4),\n",
    "                     'r2': r2.round(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Baseline model - only predictor is gender - linear regression\n",
    "\n",
    "gender = X_train_predictors[:,0].reshape(-1,1)\n",
    "#gender = gender.reshape(-1,1)\n",
    "reg = LinearRegression().fit(gender, y_train)\n",
    "\n",
    "preds =  reg.predict(gender)\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': 'linear-gender',\n",
    "                         'rmse': performance.round(4),\n",
    "                         'r2': r2.round(4)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "### Baseline model - only predictor is gender - linear regression - PD version\n",
    "\n",
    "gender = X_train.loc[:, ['gender']]\n",
    "#gender = gender.reshape(-1,1)\n",
    "reg = LinearRegression().fit(gender, y_train)\n",
    "\n",
    "preds =  reg.predict(gender)\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': 'linear-gender',\n",
    "                         'rmse': performance.round(4),\n",
    "                         'r2': r2.round(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### full linear model \n",
    "# cv? - this is not working out \n",
    "# regularization? \n",
    "\n",
    "reg = LinearRegression().fit(X_train_predictors_scaled, y_train)\n",
    "\n",
    "preds =  reg.predict(X_train_predictors_scaled)\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': 'linear-full-scaled',\n",
    "                         'rmse': performance.round(4),\n",
    "                         'r2': r2.round(4)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "### full linear model --- PANDAS VERSION\n",
    "# cv? - this is not working out \n",
    "# regularization? \n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "preds =  reg.predict(X_train)\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': 'linear-full-scaled',\n",
    "                         'rmse': performance.round(4),\n",
    "                         'r2': r2.round(4)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code below with attempt of CV needs to be fixed\n",
    "Models need to be actually fitted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)  # 5-fold cross-validation\n",
    "\n",
    "# Perform cross-validation with RMSE as the scoring metric\n",
    "scores = cross_val_score(model, X_train_predictors_scaled, y_train, cv=kf, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Calculate the average RMSE and standard deviation\n",
    "rmse_scores = -scores  # Convert negative RMSE scores to positive\n",
    "#print(f\"Mean RMSE: {rmse_scores:.2f}\") #, Standard Deviation of RMSE: {std_rmse:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit(X_train_predictors_scaled, y_train)\n",
    "\n",
    "preds =  model_fit.predict(X_train_predictors_scaled)\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': 'linear-full-scaled-cv',\n",
    "                         'rmse': performance.round(4),\n",
    "                         'r2': r2.round(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### full model but using polynomial linear regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X_train_copy = X_train_predictors_scaled.copy()\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "X_train_copy = poly.fit_transform(X_train_copy)\n",
    "reg = LinearRegression().fit(X_train_copy, y_train)\n",
    "preds = reg.predict(X_train_copy)\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': 'poly-allpreds-3',\n",
    "                    'split': 'train',\n",
    "                    'rmse': performance.round(4),\n",
    "                    'r2': r2.round(4)})\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full model but using KNN linear regression\n",
    "\n",
    "for k in [3,5,10,20,30]:\n",
    "    neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "    neigh.fit(X_train_predictors, y_train)\n",
    "    #pkl.dump(neigh, file=open(f'example-models/knn-allpreds-{k}.pkl', 'wb')) # save the model\n",
    "\n",
    "    preds = neigh.predict(X_train_predictors)\n",
    "\n",
    "    r2 = r2_score(y_train, preds)\n",
    "    performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "    performances.append({'model': f'knn-allpreds-{k}',\n",
    "                            'split': 'train',\n",
    "                            'rmse': performance.round(4),\n",
    "                            'r2': r2.round(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "neigh.fit(X_train_predictors, y_train)\n",
    "#pkl.dump(neigh, file=open(f'example-models/knn-allpreds-{k}.pkl', 'wb')) # save the model\n",
    "\n",
    "preds = neigh.predict(X_train_predictors)\n",
    "\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': f'knn-allpreds-{k}',\n",
    "                        'split': 'train',\n",
    "                        'rmse': performance.round(4),\n",
    "                        'r2': r2.round(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Need to actually read about the different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor(random_state=42) # first, we instantiate the estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [10, 20, 100, 200, 500],\n",
    "    'max_depth' : [2, 3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': [0.3, 0.6, 0.9], # can you guess what this is, without looking at the documentation?\n",
    "    'ccp_alpha': [0.01, 0.1, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv\n",
    "cv_rfr = RandomizedSearchCV(estimator=rfreg, # I am choosing RandomizedSearchCV for speed, but you can also go for GridSearchCV :)\n",
    "                            param_distributions=param_grid,\n",
    "                            scoring='neg_mean_squared_error', # this is \"neg\" because CV wants a metric to maximize\n",
    "                            n_iter=20, # this should more likely be above 100, and in general the higher the better\n",
    "                            cv=5)\n",
    "cv_rfr.fit(X_train_predictors_scaled, y_train)\n",
    "\n",
    "# 100 min - save model in variable as with pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rfr.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forrest_model = cv_rfr.fit(X_train_predictors_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(random_forrest_model, file=open(f'models/random_forrest.pkl', 'wb')) # save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv_rfr.best_estimator_\n",
    "\n",
    "preds = model.predict(X_train_predictors_scaled)\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': 'random_forrest',\n",
    "                         'split': 'train',\n",
    "                         'rmse': performance.round(4),\n",
    "                         'r2': r2.round(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame(performances)\n",
    "sns.scatterplot(data=perf_df.sort_values(by='rmse', ascending=False), \n",
    "                y='model', \n",
    "                x='rmse', \n",
    "                marker='s', \n",
    "                hue='split', palette=['darkorange', 'grey', 'darkred'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = cv_rfr.best_estimator_.feature_importances_\n",
    "# the above computes the (normalized) total reduction of the criterion brought by that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=train.columns.tolist(), y=importances, color=sns.color_palette()[0])\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "#plt.gca().set_xticks(plt.gca().get_xticks()[::2])  # Show every 10th tick # [::10]\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make xgboost? why is it better? \n",
    "or a single decision tree before random forrest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

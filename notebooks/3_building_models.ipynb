{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building and evaluating different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do this:\n",
    "- Only use test data set\n",
    "\n",
    "Models to build:\n",
    "- a dummy model: mean of y\n",
    "- a baseline model: using only gender? \n",
    "- full model:\n",
    "    - a simple linear regression\n",
    "    - a non-parametric linear regression KNN\n",
    "    - a simple decision tree\n",
    "\n",
    "All? or only the full models should be trained using CV and should be heavily regularized (_standardize_ first?). \n",
    "All models should be compared using the same error metric: mean squarred error \n",
    "\n",
    "choosing the best model, validate it, and then test it:\n",
    "- investigate interpretability, feature importance, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'env (Python 3.12.3)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# important relevant packages \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error # MSE?? rmse? \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## random forrest og feature importance \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from xgboost import XGBRegressor\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X_train_embedded = np.load('data/train_embedded.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we want to exclude columns which are not relevant as predictors\n",
    "\n",
    "X_train_w_pca_vecs[4,0:9]\n",
    "X_train_gender = X_train_w_pca_vecs[:,0]\n",
    "X_train_predictors = X_train_w_pca_vecs[:,3:]\n",
    "\n",
    "X_train_predictors = np.hstack((X_train_gender.reshape(-1,1), X_train_predictors))\n",
    "\n",
    "X_train_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new df\n",
    "#np.save(\"data/train_embedded\", X_train_predictors, allow_pickle=True)\n",
    "# reload \n",
    "#test = np.load(\"data/train_embedded.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing embedded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize embedded data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_pred_scaled = scaler.fit_transform(X_train_predictors[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_scaled_cols = X_train_predictors[:,:3]\n",
    "#X_train_pred_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_predictors_scaled = np.hstack((non_scaled_cols, X_train_pred_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape\n",
    "X_train_predictors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dummy model  -  mean of y\n",
    "\n",
    "mean_value = y_train.mean()\n",
    "model_name = 'dummy'\n",
    "performance = np.sqrt(mean_squared_error(y_train, [mean_value]*y_train.shape[0]))\n",
    "r2 = r2_score(y_train, [mean_value]*y_train.shape[0])\n",
    "performances.append({'model': model_name,\n",
    "                     'split': 'train',\n",
    "                     'rmse': performance.round(4),\n",
    "                     'r2': r2.round(4)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Baseline model - only predictor is gender - linear regression\n",
    "\n",
    "gender = X_train_predictors[:,0].reshape(-1,1)\n",
    "#gender = gender.reshape(-1,1)\n",
    "reg = LinearRegression().fit(gender, y_train)\n",
    "\n",
    "preds =  reg.predict(gender)\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': 'linear-gender',\n",
    "                         'rmse': performance.round(4),\n",
    "                         'r2': r2.round(4)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### full linear model \n",
    "# cv? - this is not working out \n",
    "# regularization? \n",
    "\n",
    "reg = LinearRegression().fit(X_train_predictors_scaled, y_train)\n",
    "\n",
    "preds =  reg.predict(X_train_predictors_scaled)\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': 'linear-full-scaled',\n",
    "                         'rmse': performance.round(4),\n",
    "                         'r2': r2.round(4)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)  # 5-fold cross-validation\n",
    "\n",
    "# Perform cross-validation with RMSE as the scoring metric\n",
    "scores = cross_val_score(model, X_train_predictors_scaled, y_train, cv=kf, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Calculate the average RMSE and standard deviation\n",
    "rmse_scores = -scores  # Convert negative RMSE scores to positive\n",
    "#print(f\"Mean RMSE: {rmse_scores:.2f}\") #, Standard Deviation of RMSE: {std_rmse:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit(X_train_predictors_scaled, y_train)\n",
    "\n",
    "preds =  model_fit.predict(X_train_predictors_scaled)\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': 'linear-full-scaled-cv',\n",
    "                         'rmse': performance.round(4),\n",
    "                         'r2': r2.round(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### full model but using polynomial linear regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X_train_copy = X_train_predictors_scaled.copy()\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "X_train_copy = poly.fit_transform(X_train_copy)\n",
    "reg = LinearRegression().fit(X_train_copy, y_train)\n",
    "preds = reg.predict(X_train_copy)\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': 'poly-allpreds-3',\n",
    "                    'split': 'train',\n",
    "                    'rmse': performance.round(4),\n",
    "                    'r2': r2.round(4)})\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full model but using KNN linear regression\n",
    "\n",
    "for k in [3,5,10,20,30]:\n",
    "    neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "    neigh.fit(X_train_predictors, y_train)\n",
    "    #pkl.dump(neigh, file=open(f'example-models/knn-allpreds-{k}.pkl', 'wb')) # save the model\n",
    "\n",
    "    preds = neigh.predict(X_train_predictors)\n",
    "\n",
    "    r2 = r2_score(y_train, preds)\n",
    "    performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "    performances.append({'model': f'knn-allpreds-{k}',\n",
    "                            'split': 'train',\n",
    "                            'rmse': performance.round(4),\n",
    "                            'r2': r2.round(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "neigh.fit(X_train_predictors, y_train)\n",
    "#pkl.dump(neigh, file=open(f'example-models/knn-allpreds-{k}.pkl', 'wb')) # save the model\n",
    "\n",
    "preds = neigh.predict(X_train_predictors)\n",
    "\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': f'knn-allpreds-{k}',\n",
    "                        'split': 'train',\n",
    "                        'rmse': performance.round(4),\n",
    "                        'r2': r2.round(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor(random_state=42) # first, we instantiate the estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [10, 20, 100, 200, 500],\n",
    "    'max_depth' : [2, 3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': [0.3, 0.6, 0.9], # can you guess what this is, without looking at the documentation?\n",
    "    'ccp_alpha': [0.01, 0.1, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv\n",
    "cv_rfr = RandomizedSearchCV(estimator=rfreg, # I am choosing RandomizedSearchCV for speed, but you can also go for GridSearchCV :)\n",
    "                            param_distributions=param_grid,\n",
    "                            scoring='neg_mean_squared_error', # this is \"neg\" because CV wants a metric to maximize\n",
    "                            n_iter=20, # this should more likely be above 100, and in general the higher the better\n",
    "                            cv=5)\n",
    "cv_rfr.fit(X_train_predictors_scaled, y_train)\n",
    "\n",
    "# 100 min - save model in variable as with pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rfr.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forrest_model = cv_rfr.fit(X_train_predictors_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(random_forrest_model, file=open(f'models/random_forrest.pkl', 'wb')) # save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv_rfr.best_estimator_\n",
    "\n",
    "preds = model.predict(X_train_predictors_scaled)\n",
    "r2 = r2_score(y_train, preds)\n",
    "performance = np.sqrt(mean_squared_error(y_train, preds))\n",
    "performances.append({'model': 'random_forrest',\n",
    "                         'split': 'train',\n",
    "                         'rmse': performance.round(4),\n",
    "                         'r2': r2.round(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame(performances)\n",
    "sns.scatterplot(data=perf_df.sort_values(by='rmse', ascending=False), \n",
    "                y='model', \n",
    "                x='rmse', \n",
    "                marker='s', \n",
    "                hue='split', palette=['darkorange', 'grey', 'darkred'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = cv_rfr.best_estimator_.feature_importances_\n",
    "# the above computes the (normalized) total reduction of the criterion brought by that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=train.columns.tolist(), y=importances, color=sns.color_palette()[0])\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "#plt.gca().set_xticks(plt.gca().get_xticks()[::2])  # Show every 10th tick # [::10]\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
